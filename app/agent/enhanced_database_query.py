import asyncio
import json
import time
from typing import Any, Callable, Dict, List, Optional

from pydantic import Field

from app.agent.mcp import MCPAgent
from app.logger import logger
from app.prompt.database_query import (
    DATABASE_QUERY_NEXT_STEP,
    DATABASE_QUERY_SYSTEM_PROMPT,
)
from app.schema import AgentState


class EnhancedDatabaseQueryAgent(MCPAgent):
    """
    å¢å¼ºå‹æ•°æ®åº“æŸ¥è¯¢ä»£ç† (Enhanced Database Query Agent)

    åŠŸèƒ½ï¼š
    - æ™ºèƒ½è¿æ¥æ•°æ®åº“å¹¶æ‰§è¡ŒæŸ¥è¯¢
    - è‡ªé€‚åº”å…ƒæ•°æ®åŠ è½½ç­–ç•¥ï¼ˆå…¨é‡/æŒ‰éœ€ï¼‰
    - æ”¯æŒä¸­æ–‡çŠ¶æ€åé¦ˆ
    - è‡ªåŠ¨ç¼“å­˜è¡¨ç»“æ„ä»¥æå‡æ€§èƒ½
    """

    name: str = "enhanced_database_query_agent"
    description: str = "ä¸€ä¸ªé€šè¿‡æŸ¥è¯¢æ•°æ®åº“æ¥å›ç­”é—®é¢˜çš„å¢å¼ºå‹ä»£ç†ã€‚"

    # ä½¿ç”¨æ•°æ®åº“ä¸“ç”¨çš„ç³»ç»Ÿæç¤ºè¯
    system_prompt: str = DATABASE_QUERY_SYSTEM_PROMPT
    next_step_prompt: str = DATABASE_QUERY_NEXT_STEP

    # å…ƒæ•°æ®ç¼“å­˜é…ç½®
    metadata_cache: dict = Field(default_factory=dict)
    cache_expiry: int = Field(default=1800, description="ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰")
    last_cache_update: float = Field(default=0.0, description="ä¸Šæ¬¡ç¼“å­˜æ›´æ–°æ—¶é—´")

    # æŸ¥è¯¢çŠ¶æ€è¿½è¸ª
    query_results: Optional[str] = None
    max_retries: int = Field(default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•°")

    # åŠ è½½ç­–ç•¥é…ç½®
    metadata_injected: bool = Field(default=False, description="å…ƒæ•°æ®æ˜¯å¦å·²æ³¨å…¥")
    loading_strategy: str = Field(
        default="auto", description="åŠ è½½ç­–ç•¥: auto/full/on_demand"
    )
    table_count_threshold: int = Field(default=15, description="ç­–ç•¥åˆ‡æ¢é˜ˆå€¼")

    # çŠ¶æ€å›è°ƒå‡½æ•°
    _status_callback: Optional[Callable[[str], None]] = None

    async def initialize(
        self,
        connection_type: str = "stdio",
        command: Optional[str] = None,
        args: Optional[List[str]] = None,
        loading_strategy: str = "on_demand",
        status_callback: Optional[Callable[[str], None]] = None,
    ) -> None:
        """
        åˆå§‹åŒ–ä»£ç†å¹¶è¿æ¥MCPæœåŠ¡å™¨

        å‚æ•°:
            connection_type: è¿æ¥ç±»å‹ (stdio/sse)
            command: MCPæœåŠ¡å™¨å‘½ä»¤
            args: MCPæœåŠ¡å™¨å‚æ•°
            loading_strategy: å…ƒæ•°æ®åŠ è½½ç­–ç•¥
            status_callback: çŠ¶æ€å›è°ƒå‡½æ•°
        """
        self._status_callback = status_callback
        self._report_status("ğŸ”Œ æ­£åœ¨è¿æ¥MCPæœåŠ¡å™¨...")

        await super().initialize(
            connection_type=connection_type,
            command=command,
            args=args,
        )

        # é‡ç½®çŠ¶æ€
        self.query_results = None
        self.metadata_cache = {}
        self.last_cache_update = 0.0
        self.metadata_injected = False
        self.loading_strategy = loading_strategy

        # é¢„åŠ è½½åŸºç¡€å…ƒæ•°æ®
        self._report_status("ğŸ“Š æ­£åœ¨é¢„åŠ è½½æ•°æ®åº“å…ƒæ•°æ®...")
        await self._preload_basic_metadata()

        # é…ç½®å…ƒæ•°æ®ç­–ç•¥
        self._report_status("âš™ï¸ æ­£åœ¨é…ç½®å…ƒæ•°æ®åŠ è½½ç­–ç•¥...")
        await self._inject_metadata_with_strategy()

        self._report_status("âœ… åˆå§‹åŒ–å®Œæˆ")

    def _report_status(self, message: str):
        """æŠ¥å‘Šå½“å‰çŠ¶æ€"""
        if self._status_callback:
            self._status_callback(message)
        logger.info(message)

    async def reset(self):
        """é‡ç½®ä»£ç†çŠ¶æ€ï¼ˆä¿ç•™è¿æ¥ï¼‰"""
        self.query_results = None
        self.messages = []

    async def _preload_basic_metadata(self):
        """é¢„åŠ è½½åŸºç¡€å…ƒæ•°æ®ï¼ˆè¡¨åˆ—è¡¨ï¼‰"""
        current_time = time.time()

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        if (current_time - self.last_cache_update) < self.cache_expiry:
            return

        try:
            # è°ƒç”¨MCPå·¥å…·è·å–è¡¨åˆ—è¡¨
            tables_result = await self._execute_mcp_tool("list_tables", {})
            tables_data = json.loads(tables_result)

            # æ›´æ–°ç¼“å­˜
            self.metadata_cache = {
                "tables": tables_data,
                "schemas": {},
                "timestamp": current_time,
            }
            self.last_cache_update = current_time

            table_count = len(tables_data.get("data", []))
            self._report_status(f"ğŸ“‹ å‘ç° {table_count} ä¸ªæ•°æ®è¡¨")
        except Exception as e:
            logger.warning(f"Failed to preload basic metadata: {e}")
            self._report_status(f"âš ï¸ å…ƒæ•°æ®é¢„åŠ è½½å¤±è´¥: {e}")

    async def _inject_metadata_with_strategy(self):
        """æ ¹æ®ç­–ç•¥æ³¨å…¥å…ƒæ•°æ®åˆ°ç³»ç»Ÿæç¤ºè¯"""
        if self.metadata_injected:
            return

        try:
            tables_data = self.metadata_cache.get("tables", {})
            if not tables_data or "data" not in tables_data:
                logger.warning("No tables found in database")
                return

            table_count = len(tables_data["data"])

            # è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
            if self.loading_strategy == "auto":
                strategy = (
                    "full" if table_count < self.table_count_threshold else "on_demand"
                )
            else:
                strategy = self.loading_strategy

            self._report_status(f"ğŸ“ ä½¿ç”¨åŠ è½½ç­–ç•¥: {strategy}")

            if strategy == "full":
                await self._inject_full_metadata(tables_data)
            else:
                await self._inject_relationship_metadata(tables_data)

            self.metadata_injected = True

        except Exception as e:
            logger.error(f"Failed to inject metadata: {e}", exc_info=True)
            self._report_status(f"âŒ å…ƒæ•°æ®æ³¨å…¥å¤±è´¥: {e}")

    async def _inject_full_metadata(self, tables_data: dict):
        """æ³¨å…¥å®Œæ•´å…ƒæ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰è¡¨ç»“æ„ï¼‰"""
        table_count = len(tables_data["data"])
        self._report_status(f"ğŸ“¥ æ­£åœ¨åŠ è½½ {table_count} ä¸ªè¡¨çš„å®Œæ•´ç»“æ„...")

        metadata_text = "\n\n## ğŸ“Š æ•°æ®åº“ç»“æ„ä¿¡æ¯ (å®Œæ•´)\n\n"

        # å¹¶è¡ŒåŠ è½½æ‰€æœ‰è¡¨ç»“æ„
        table_names = [t.get("name") for t in tables_data["data"] if t.get("name")]
        schemas = await self._parallel_load_schemas(table_names)

        # æ›´æ–°ç¼“å­˜
        for table_name, schema in schemas.items():
            self.metadata_cache["schemas"][table_name] = {
                "data": schema,
                "cached_at": time.time(),
            }

        # æ„å»ºæç¤ºè¯æ–‡æœ¬
        for table_info in tables_data["data"]:
            table_name = table_info.get("name", "Unknown")
            table_desc = table_info.get("description", "")

            metadata_text += f"### `{table_name}`\n"
            if table_desc:
                metadata_text += f"**è¯´æ˜**: {table_desc}\n"

            schema = schemas.get(table_name)
            if schema and "data" in schema:
                columns = schema["data"].get("columns", [])
                if columns:
                    metadata_text += "\n**å­—æ®µ**:\n"
                    for col in columns:
                        col_name = col.get("name", "")
                        col_type = col.get("type", "")
                        nullable = "NULL" if col.get("nullable") else "NOT NULL"
                        key = col.get("key", "")
                        key_info = f" [{key}]" if key else ""
                        metadata_text += (
                            f"- `{col_name}` ({col_type}) {nullable}{key_info}\n"
                        )

                foreign_keys = schema["data"].get("foreign_keys", [])
                if foreign_keys:
                    metadata_text += "\n**å¤–é”®**: "
                    fk_list = []
                    for fk in foreign_keys:
                        if isinstance(fk, dict):
                            fk_list.append(
                                f"`{fk.get('column')}` â†’ `{fk.get('referenced_table')}.{fk.get('referenced_column')}`"
                            )
                    metadata_text += ", ".join(fk_list) + "\n"

            metadata_text += "\n"

        self.system_prompt = self.system_prompt + metadata_text
        self._report_status("âœ… å®Œæ•´å…ƒæ•°æ®å·²æ³¨å…¥")

    async def _inject_relationship_metadata(self, tables_data: dict):
        """æ³¨å…¥å…³ç³»å…ƒæ•°æ®ï¼ˆä»…åŒ…å«è¡¨åå’Œå…³ç³»ï¼ŒæŒ‰éœ€åŠ è½½è¯¦æƒ…ï¼‰"""
        table_count = len(tables_data["data"])
        self._report_status(f"ğŸ”— æ­£åœ¨åŠ è½½ {table_count} ä¸ªè¡¨çš„å…³ç³»ä¿¡æ¯...")

        metadata_text = "\n\n## ğŸ“Š æ•°æ®åº“å…³ç³»ä¿¡æ¯ (æŒ‰éœ€åŠ è½½)\n\n"
        metadata_text += "ä»¥ä¸‹æ˜¯è¡¨åˆ—è¡¨åŠå…¶å…³ç³»ã€‚è¯¦ç»†ç»“æ„å°†æŒ‰éœ€åŠ è½½ã€‚\n\n"

        table_names = [t.get("name") for t in tables_data["data"] if t.get("name")]
        relationships = await self._parallel_load_relationships(table_names)

        # æŒ‰ç±»åˆ«åˆ†ç»„
        categorized = {}
        for table_info in tables_data["data"]:
            table_name = table_info.get("name", "Unknown")
            table_desc = table_info.get("description", "")
            category = table_info.get("category", "å…¶ä»–")

            if category not in categorized:
                categorized[category] = []
            categorized[category].append(
                {
                    "name": table_name,
                    "desc": table_desc,
                    "relationships": relationships.get(table_name, []),
                }
            )

        # æ„å»ºæç¤ºè¯æ–‡æœ¬
        for category, tables in categorized.items():
            if category != "å…¶ä»–":
                metadata_text += f"### {category}\n"

            for table in tables:
                table_name = table["name"]
                table_desc = table["desc"]
                rels = table["relationships"]

                metadata_text += f"- **`{table_name}`**"
                if table_desc:
                    metadata_text += f": {table_desc}"

                if rels:
                    metadata_text += f"\n  - å…³è”: {', '.join(rels)}"
                metadata_text += "\n"

            metadata_text += "\n"

        self.system_prompt = self.system_prompt + metadata_text
        self._report_status("âœ… å…³ç³»å…ƒæ•°æ®å·²æ³¨å…¥")

    async def _parallel_load_schemas(self, table_names: List[str]) -> Dict[str, dict]:
        """å¹¶è¡ŒåŠ è½½å¤šä¸ªè¡¨çš„ç»“æ„"""

        async def load_schema(table_name: str):
            try:
                result = await self._execute_mcp_tool(
                    "get_table_schema", {"table": table_name}
                )
                return table_name, json.loads(result)
            except Exception as e:
                logger.warning(f"Failed to load schema for {table_name}: {e}")
                return table_name, None

        tasks = [load_schema(name) for name in table_names]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        schemas = {}
        for result in results:
            if isinstance(result, tuple) and result[1] is not None:
                schemas[result[0]] = result[1]

        return schemas

    async def _parallel_load_relationships(
        self, table_names: List[str]
    ) -> Dict[str, List[str]]:
        """å¹¶è¡ŒåŠ è½½å¤šä¸ªè¡¨çš„å…³ç³»"""

        async def get_relationships(table_name: str):
            try:
                result = await self._execute_mcp_tool(
                    "get_table_schema", {"table": table_name}
                )
                schema = json.loads(result)

                relationships = []
                if "data" in schema:
                    fks = schema["data"].get("foreign_keys", [])
                    for fk in fks:
                        if isinstance(fk, dict):
                            ref_table = fk.get("referenced_table")
                            if ref_table:
                                relationships.append(ref_table)

                return table_name, relationships
            except Exception as e:
                logger.warning(f"Failed to get relationships for {table_name}: {e}")
                return table_name, []

        tasks = [get_relationships(name) for name in table_names]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        relationships = {}
        for result in results:
            if isinstance(result, tuple):
                relationships[result[0]] = result[1]

        return relationships

    async def _handle_special_tool(self, name: str, result: Any, **kwargs) -> None:
        """å¤„ç†ç‰¹æ®Šå·¥å…·è°ƒç”¨å¹¶æŠ¥å‘ŠçŠ¶æ€"""
        tool_input = kwargs.get("tool_input", {})

        if "get_table_schema" in name:
            self._report_status("ğŸ“¥ æ­£åœ¨è·å–è¡¨ç»“æ„...")
        elif "execute_sql" in name:
            self._report_status("âš¡ æ­£åœ¨æ‰§è¡ŒSQLæŸ¥è¯¢...")
        elif "list_tables" in name:
            self._report_status("ğŸ“‹ æ­£åœ¨è·å–è¡¨åˆ—è¡¨...")
        else:
            clean_name = name.split("_")[-1] if "_" in name else name
            self._report_status(f"ğŸ”§ æ­£åœ¨æ‰§è¡Œ: {clean_name}")

        await super()._handle_special_tool(name, result, **kwargs)

    def _should_finish_execution(self, name: str, **kwargs) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸæ‰§è¡Œ"""
        return name.lower() == "terminate" or "terminate" in name.lower()

    async def run(
        self,
        request: Optional[str] = None,
        status_callback: Optional[Callable[[str], None]] = None,
        **kwargs,
    ) -> str:
        """è¿è¡Œä»£ç†"""
        if status_callback:
            self._status_callback = status_callback

        if self.state == AgentState.IDLE and self.current_step == 0:
            self.query_results = None
            self._report_status("ğŸ¤” æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...")

        try:
            result = await super(MCPAgent, self).run(
                request, auto_cleanup=False, **kwargs
            )
        finally:
            pass

        self.current_step = 0
        self.state = AgentState.IDLE

        # å°è¯•ä»æ¶ˆæ¯å†å²ä¸­è·å–æœ€åçš„åŠ©æ‰‹å›å¤
        if hasattr(self, "messages") and self.messages:
            for message in reversed(self.messages):
                if hasattr(message, "role") and message.role == "assistant":
                    content = message.content.strip() if message.content else ""
                    if len(content) > 10 and not content.startswith("Observed output"):
                        return content

        # å°è¯•ä»terminateå·¥å…·è¾“å‡ºä¸­è·å–ç»“æœ
        if "Observed output of cmd `terminate` executed:" in result:
            parts = result.split("Observed output of cmd `terminate` executed:")
            if len(parts) > 1:
                return parts[1].strip()

        return result or "æŸ¥è¯¢å®Œæˆä½†æœªè·å¾—ç»“æœ"

    async def _execute_mcp_tool(self, tool_name: str, arguments: dict):
        """æ‰§è¡ŒMCPå·¥å…·"""
        full_tool_name = None

        # æŸ¥æ‰¾å®Œæ•´çš„å·¥å…·åç§°
        for tool_key in self.available_tools.tool_map.keys():
            if tool_key.endswith(f"_{tool_name}"):
                full_tool_name = tool_key
                break

        if not full_tool_name and tool_name in self.available_tools.tool_map:
            full_tool_name = tool_name

        if not full_tool_name:
            available_tool_names = list(self.available_tools.tool_map.keys())
            raise ValueError(
                f"Tool {tool_name} not found. Available tools: {available_tool_names}"
            )

        result = await self.available_tools.execute(
            name=full_tool_name, tool_input=arguments
        )

        return result.output if hasattr(result, "output") else str(result)

    async def get_cached_tables(self):
        """è·å–ç¼“å­˜çš„è¡¨åˆ—è¡¨ï¼ˆç”¨äºæµ‹è¯•è¿æ¥ï¼‰"""
        await self._preload_basic_metadata()
        return self.metadata_cache.get("tables", {})

    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        self._report_status("ğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")
        await super().cleanup()
